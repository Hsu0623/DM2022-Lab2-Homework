{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Student Information\n",
    "Name: 許詠晴\n",
    "\n",
    "Student ID: 111062575\n",
    "\n",
    "GitHub ID: Hsu0623\n",
    "\n",
    "Kaggle name: Hsu1004\n",
    "\n",
    "Kaggle private scoreboard snapshot:0.40672\n",
    "\n",
    "[Snapshot](img/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First: __This part is worth 30% of your grade.__ Do the **take home** exercises in the [DM2022-Lab2-master Repo](https://github.com/keziatamus/DM2022-Lab2-Master). You may need to copy some cells from the Lab notebook to this notebook. \n",
    "\n",
    "\n",
    "2. Second: __This part is worth 30% of your grade.__ Participate in the in-class [Kaggle Competition](https://www.kaggle.com/competitions/dm2022-isa5810-lab2-homework) regarding Emotion Recognition on Twitter by this link https://www.kaggle.com/t/2b0d14a829f340bc88d2660dc602d4bd. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20% of the 30% available for this section.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (60-x)/6 + 20 points, where x is your ranking in the leaderboard (ie. If you rank 3rd your score will be (60-3)/6 + 20 = 29.5% out of 30%)   \n",
    "    Submit your last submission __BEFORE the deadline (Nov. 22th 11:59 pm, Tuesday)_. Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the **img** folder of this repository and rerun the cell **Student Information**.\n",
    "    \n",
    "\n",
    "3. Third: __This part is worth 30% of your grade.__ A report of your work developping the model for the competition (You can use code and comment it). This report should include what your preprocessing steps, the feature engineering steps and an explanation of your model. You can also mention different things you tried and insights you gained. \n",
    "\n",
    "\n",
    "4. Fourth: __This part is worth 10% of your grade.__ It's hard for us to follow if your code is messy :'(, so please **tidy up your notebook** and **add minimal comments where needed**.\n",
    "\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding e-learn assignment.\n",
    "\n",
    "Make sure to commit and save your changes to your repository __BEFORE the deadline (Nov. 25th 11:59 pm, Friday)__. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Begin Assignment Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First: Do the take home exercises in the DM2022-Lab2-master Repo\n",
    "#### address of DM2022-Lab2-master:  https://github.com/Hsu0623/DM2022-Lab2-Master/blob/main/DM2022-Lab2-Master.ipynb "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to take a screenshot of your position at the end of the competition and store it as '''pic0.png''' under the img folder of this repository and rerun the cell Student Information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is my code and comment.\n",
    "\n",
    "This code runs in Google colab (https://colab.research.google.com/drive/1vSvG0GHHc5UI68YyXMggwcnU4BVHwPjL#scrollTo=74UHu7rBXCwy), because my PC is poor.\n",
    "\n",
    "However, I'm a free number on Google Colab and am plagued by RAM limitations.\n",
    "\n",
    "So, I had to run some cells, save the current state (save data and output as .json, .pickle, etc.), restart \n",
    "the kernel, read the saved file, and rerun the cells, repeatly and repeatly again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import needed module firstly\n",
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read json file\n",
    "* read tweets_DM.json\n",
    "  * only read tweet_id and text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/data_mining/lab2/tweets_DM.json\"\n",
    "\n",
    "ids = []\n",
    "texts = []\n",
    "\n",
    "with open(file_path, 'r') as fp:\n",
    "  for line in fp:\n",
    "    data = json.loads(line)\n",
    "    ids.append(data[\"_source\"][\"tweet\"][\"tweet_id\"])\n",
    "    texts.append(data[\"_source\"][\"tweet\"][\"text\"])\n",
    "\n",
    "df = pd.DataFrame(list(zip(ids,texts)), columns=[\"tweet_id\", \"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read data_identification.csv in order to seperate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/data_mining/lab2/data_identification.csv\"\n",
    "\n",
    "with open(file_path, 'r') as fp:\n",
    "  df_id = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read emotion.csv as train label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"/content/drive/MyDrive/data_mining/lab2/emotion.csv\"\n",
    "\n",
    "with open(file_path, 'r') as fp:\n",
    "  df_emotion = pd.read_csv(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emotion[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* merge data and identification by tweet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_id, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* seperate data into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(df.identification)\n",
    "df_train = grouped.get_group(\"train\")\n",
    "df_test = grouped.get_group(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_emotion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* finally, merge emotion label and train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(df_train, df_emotion, on=\"tweet_id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* eliminate identification because it is unuseful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.pop(\"identification\")\n",
    "df_test.pop(\"identification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* show train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing\n",
    "* using nltk.tokenize to tokenize setence(data[text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "df_train[\"tokens\"] = df_train[\"text\"].apply(lambda x: word_tokenize(x))\n",
    "df_test[\"tokens\"] = df_test[\"text\"].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* save data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_pickle(\"/content/drive/MyDrive/data_mining/lab2/df_train.pkl\")\n",
    "df_test.to_pickle(\"/content/drive/MyDrive/data_mining/lab2/df_test.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### restart kernel and load data\n",
    "* because executing above codes spend lost of RAM and time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"/content/drive/MyDrive/data_mining/lab2/df_train.pkl\")\n",
    "\n",
    "test_df = pd.read_pickle(\"/content/drive/MyDrive/data_mining/lab2/df_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_train))\n",
    "print(len(train_df))\n",
    "print(len(df_test))\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### continue to data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using embedding to change the type of X_train/X_test(string) to number.\n",
    "* because the type of the input of deep leraning model needs number "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* firstly, Onehot encoding emotion(Y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train_df[\"emotion\"]\n",
    "print(\"Before encoding label:\")\n",
    "print(Y_train[:5])\n",
    "\n",
    "print(\"After encoding:\")\n",
    "# integer encode\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(Y_train)\n",
    "print(integer_encoded[:5])\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "Y_train_onehot = onehot_encoder.fit_transform(integer_encoded)\n",
    "print(Y_train_onehot[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* save Y_train_onehot endcoding file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"/content/drive/MyDrive/data_mining/lab2/Y_train_onehot.npy\", Y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_onehot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training w2v model with X_train data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "## setting\n",
    "vector_dim = 150\n",
    "window_size = 3\n",
    "min_count = 1\n",
    "training_epochs = 10\n",
    "\n",
    "## model\n",
    "w2v_model = Word2Vec(sentences=X_train, size=vector_dim, window=window_size, min_count=min_count, iter=training_epochs)\n",
    "print(\"Word2Vec trains OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* save w2v weights and result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"/content/drive/MyDrive/data_mining/lab2/word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load if w2v_model is pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec.load(\"/content/drive/MyDrive/data_mining/lab2/word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* convert all string data into word vector and save them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### turn each word into vector and save\n",
    "* Due to the limitation of RAM, I have to split 1.4 million training data into 15 pieces (100,000 pieces each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_w2v_train = np.array([np.mean(w2v_model.wv[string],axis=0) for string in X_train[1200000:1300000]])\n",
    "# X_w2v_train = np.array([np.mean(w2v_model.wv[string],axis=0) for string in X_train[1300000:1400000]])\n",
    "X_w2v_train = np.array([np.mean(w2v_model.wv[string],axis=0) for string in X_train[1400000:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/data_mining/lab2/X_w2v_train_1455563.pickle\", \"wb\") as fp:   #Pickling\n",
    "  pickle.dump(X_w2v_train, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### turn each testing word into vectors and save\n",
    "\n",
    "Althouh I have all word vectors of data, the memory size usage is tooooooo big\n",
    "\n",
    "Thus, averaging each word vectors of a setence as the representation of the setence\n",
    "\n",
    "And save the average files into a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[\"tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* When a test word is encountered that does not appear in the training words, it is replaced with a zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v_test = []\n",
    "\n",
    "for string in X_test[400000:]:\n",
    "  tmp = np.array([])\n",
    "  for word in string:\n",
    "    try:\n",
    "      vec = w2v_model.wv[word]\n",
    "    except:\n",
    "      vec = np.zeros((1,150))\n",
    "    if tmp.shape==(0,):\n",
    "      tmp = vec\n",
    "    else:\n",
    "      tmp=np.vstack((tmp,vec))\n",
    "  X_w2v_test.append(np.mean(tmp,axis=0))\n",
    "\n",
    "\n",
    "X_w2v_test = np.array(X_w2v_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/data_mining/lab2/X_w2v_test_411972.pickle\", \"wb\") as fp:   #Pickling\n",
    "  pickle.dump(X_w2v_test, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### finally, the data preprocessing is finished.\n",
    "the shape of X_train is (1455563, 150)\n",
    "\n",
    "the shape of X_test is (411972, 150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## start to classify which emotion the setence is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* restrat kernel because the limitation of RAM\n",
    "#### load all required data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* load X_train, Y_train, and X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/data_mining/lab2/X_avg_train.pickle\",\"rb\") as fp:   #Pickling\n",
    "  X_train = pickle.load(fp)\n",
    "\n",
    "Y_train_onehot = np.load(\"/content/drive/MyDrive/data_mining/lab2/Y_train_onehot.npy\")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/content/drive/MyDrive/data_mining/lab2/X_avg_test.pickle\",\"rb\") as fp:   #Pickling\n",
    "  X_test = pickle.load(fp)\n",
    "\n",
    "\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deep learning Dense -  build classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = tf.keras.layers.Input(shape=(150))\n",
    "x = tf.keras.layers.Dense(128, activation='relu')(input)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "output = tf.keras.layers.Dense(8, activation='softmax')(x)\n",
    "\n",
    "cls_model = tf.keras.models.Model(inputs=input,outputs=output)\n",
    "\n",
    "cls_model.compile(optimizer='adam',\n",
    "         loss='categorical_crossentropy',\n",
    "         metrics=['accuracy'])\n",
    "\n",
    "cls_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training setting\n",
    "epochs = 25\n",
    "batch_size = 64\n",
    "\n",
    "# training!\n",
    "history = cls_model.fit(X_train, Y_train_onehot, epochs=epochs, batch_size=batch_size)\n",
    "print('training finish')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_result = cls_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the predict result into csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* turn oneHot encoding into emtion(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = [\"anger\",\"anticipation\",\"digust\",\"fear\",\"joy\",\"sadness\",\"surprise\",\"trust\"]\n",
    "pred_classes = [map[np.argmax(pred, axis=None, out=None)] for pred in pred_result]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* getting tweet_ids and combine it with emtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = pd.read_pickle(\"/content/drive/MyDrive/data_mining/lab2/df_test.pkl\")\n",
    "test_id = test_id[\"tweet_id\"].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* write predict result into csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(\"/content/drive/MyDrive/data_mining/lab2/pre_test0.csv\", \"w\") as fp:\n",
    "  write = csv.writer(fp)\n",
    "  write.writerows([(\"id\",\"emotion\")])\n",
    "  write.writerows(zip(test_id,pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
